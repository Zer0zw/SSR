{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262e0ff7",
   "metadata": {},
   "source": [
    "调用包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1eff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import math\n",
    "from pathlib import Path\n",
    "from random import sample\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724b9fa",
   "metadata": {},
   "source": [
    "groundTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4a22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************************************************\n",
    "# Normal\n",
    "# ************************************************************\n",
    "def read_json(file_path):\n",
    "    # 打开文件并读取内容\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def calculate_metrics_fromLists(groundTruth_list, model_list):\n",
    "    # 统一转化为小写集合\n",
    "    groundTruth_lower_set = set([item.lower() for item in groundTruth_list])\n",
    "    model_lower_set = set([item.lower() for item in model_list])\n",
    "\n",
    "    # 计算TP, FP, FN, TN\n",
    "    # 将两个列表转换为集合进行计算\n",
    "    true_positives = len(groundTruth_lower_set & model_lower_set)\n",
    "    false_positives = len(model_lower_set - groundTruth_lower_set)\n",
    "    false_negatives = len(groundTruth_lower_set - model_lower_set)\n",
    "    true_negatives = 0  # 这个对于集合而言不适用\n",
    "    \n",
    "    # 计算Precision, Recall, Accuracy, F1 Score\n",
    "    if true_positives + false_positives > 0:\n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    if true_positives + false_negatives > 0:\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    accuracy = true_positives / (true_positives + false_positives + false_negatives) if (true_positives + false_positives + false_negatives) > 0 else 1.0\n",
    "    \n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    else:\n",
    "        f1 = 0.0\n",
    "    \n",
    "    # 将每个类别的值保存到dict中\n",
    "    metrics_dict = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    }\n",
    "    \n",
    "    return metrics_dict\n",
    "\n",
    "# 从指定文件夹中获取项目名称list\n",
    "def get_projectNams_from_folder(_groundTruth_folder_path):\n",
    "    # 获取文件夹中的所有文件\n",
    "    files = os.listdir(_groundTruth_folder_path)\n",
    "    \n",
    "    # 过滤出所有以 .json 结尾的文件，并去掉文件后缀\n",
    "    project_names_list = [os.path.splitext(file)[0] for file in files if file.endswith('.json')]\n",
    "    \n",
    "    return project_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d37d6165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************************************************\n",
    "# DeFi Staking Model metrics\n",
    "# ************************************************************\n",
    "def get_model_metrics(_groundTruth_json_path, _model_json_path):\n",
    "    _metrics_dict = {}\n",
    "\n",
    "    _groundTruth_dict = read_json(_groundTruth_json_path)\n",
    "    _model_dict = read_json(_model_json_path)\n",
    "\n",
    "    _model_groundTruth_dict = _groundTruth_dict[\"Model\"]\n",
    "\n",
    "    # Variables Model metrics\n",
    "    _variables_model_groundTruth_dict = _model_groundTruth_dict[\"Variables\"]\n",
    "    _variables_model_dict = _model_dict[\"Variables\"]\n",
    "\n",
    "    _variables_metrics_dict = get_variables_model_metrics(_variables_model_groundTruth_dict, _variables_model_dict)\n",
    "    _metrics_dict[\"Variables\"] = _variables_metrics_dict\n",
    "\n",
    "    # Functions Model metrics\n",
    "    _functions_model_groundTruth_dict = _model_groundTruth_dict[\"Functions\"]\n",
    "    _functions_model_dict = _model_dict[\"Functions\"]\n",
    "\n",
    "    _functions_metrics_dict = get_functions_model_metrics(_functions_model_groundTruth_dict, _functions_model_dict)\n",
    "    _metrics_dict[\"Functions\"] = _functions_metrics_dict\n",
    "\n",
    "    # Calculations Model metrics\n",
    "    _calculations_model_groundTruth_dict = _model_groundTruth_dict[\"Calculations\"]\n",
    "    _calculations_model_dict = _model_dict[\"Calculations\"]\n",
    "\n",
    "    _calculations_metrics_dict = get_calculations_model_metrics(_calculations_model_groundTruth_dict, _calculations_model_dict)\n",
    "    _metrics_dict[\"Calculations\"] = _calculations_metrics_dict\n",
    "\n",
    "    # Avg\n",
    "    _avg_accuracy = np.mean([_metrics_dict[\"Variables\"][\"Mean\"][\"Accuracy\"], _metrics_dict[\"Functions\"][\"Mean\"][\"Accuracy\"], _metrics_dict[\"Calculations\"][\"Mean\"][\"Accuracy\"]])\n",
    "    _avg_precision = np.mean([_metrics_dict[\"Variables\"][\"Mean\"][\"Precision\"], _metrics_dict[\"Functions\"][\"Mean\"][\"Precision\"], _metrics_dict[\"Calculations\"][\"Mean\"][\"Precision\"]])\n",
    "    _avg_recall = np.mean([_metrics_dict[\"Variables\"][\"Mean\"][\"Recall\"], _metrics_dict[\"Functions\"][\"Mean\"][\"Recall\"], _metrics_dict[\"Calculations\"][\"Mean\"][\"Recall\"]])\n",
    "    _avg_f1_score = np.mean([_metrics_dict[\"Variables\"][\"Mean\"][\"F1 Score\"], _metrics_dict[\"Functions\"][\"Mean\"][\"F1 Score\"], _metrics_dict[\"Calculations\"][\"Mean\"][\"F1 Score\"]])\n",
    "\n",
    "    _metrics_dict[\"Mean\"] = {\n",
    "        \"Accuracy\": _avg_accuracy,\n",
    "        \"Precision\": _avg_precision,\n",
    "        \"Recall\": _avg_recall,\n",
    "        \"F1 Score\": _avg_f1_score\n",
    "    }\n",
    "\n",
    "    return _metrics_dict\n",
    "\n",
    "# Variables\n",
    "def get_variables_model_metrics(_variables_model_groundTruth_dict, variables_model_dict):\n",
    "    _variables_metrics_dict = {}\n",
    "\n",
    "    _accuracies_list = []\n",
    "    _precisions_list = []\n",
    "    _recalls_list = []\n",
    "    _f1_scores_list = []\n",
    "\n",
    "    for key in _variables_model_groundTruth_dict.keys():\n",
    "        _groundTruth_list = _variables_model_groundTruth_dict[key]\n",
    "        _model_list = variables_model_dict[key]\n",
    "\n",
    "        _metrics_dict_perKey = calculate_metrics_fromLists(_groundTruth_list, _model_list)\n",
    "\n",
    "        _accuracies_list.append(_metrics_dict_perKey[\"Accuracy\"])\n",
    "        _precisions_list.append(_metrics_dict_perKey[\"Precision\"])\n",
    "        _recalls_list.append(_metrics_dict_perKey[\"Recall\"])\n",
    "        _f1_scores_list.append(_metrics_dict_perKey[\"F1 Score\"])\n",
    "\n",
    "        _variables_metrics_dict[key] = _metrics_dict_perKey\n",
    "    \n",
    "    _avg_accuracy = np.mean(_accuracies_list)\n",
    "    _avg_precision = np.mean(_precisions_list)\n",
    "    _avg_recall = np.mean(_recalls_list)\n",
    "    _avg_f1_score = np.mean(_f1_scores_list)\n",
    "\n",
    "    _variables_metrics_dict[\"Mean\"] = {\n",
    "        \"Accuracy\": _avg_accuracy,\n",
    "        \"Precision\": _avg_precision,\n",
    "        \"Recall\": _avg_recall,\n",
    "        \"F1 Score\": _avg_f1_score\n",
    "    }\n",
    "\n",
    "    return _variables_metrics_dict\n",
    "\n",
    "# Functions\n",
    "def get_functions_model_metrics(_functions_model_groundTruth_dict, functions_model_dict):\n",
    "    _functions_metrics_dict = {}\n",
    "\n",
    "    _accuracies_list = []\n",
    "    _precisions_list = []\n",
    "    _recalls_list = []\n",
    "    _f1_scores_list = []\n",
    "\n",
    "    for key in _functions_model_groundTruth_dict.keys():\n",
    "        _groundTruth_list = _functions_model_groundTruth_dict[key]\n",
    "        _model_list = functions_model_dict[key]\n",
    "\n",
    "        _metrics_dict_perKey = calculate_metrics_fromLists(_groundTruth_list, _model_list)\n",
    "\n",
    "        _accuracies_list.append(_metrics_dict_perKey[\"Accuracy\"])\n",
    "        _precisions_list.append(_metrics_dict_perKey[\"Precision\"])\n",
    "        _recalls_list.append(_metrics_dict_perKey[\"Recall\"])\n",
    "        _f1_scores_list.append(_metrics_dict_perKey[\"F1 Score\"])\n",
    "\n",
    "        _functions_metrics_dict[key] = _metrics_dict_perKey\n",
    "    \n",
    "    _avg_accuracy = np.mean(_accuracies_list)\n",
    "    _avg_precision = np.mean(_precisions_list)\n",
    "    _avg_recall = np.mean(_recalls_list)\n",
    "    _avg_f1_score = np.mean(_f1_scores_list)\n",
    "\n",
    "    _functions_metrics_dict[\"Mean\"] = {\n",
    "        \"Accuracy\": _avg_accuracy,\n",
    "        \"Precision\": _avg_precision,\n",
    "        \"Recall\": _avg_recall,\n",
    "        \"F1 Score\": _avg_f1_score\n",
    "    }\n",
    "\n",
    "    return _functions_metrics_dict\n",
    "\n",
    "# Calculations\n",
    "def get_calculations_model_metrics(_calculations_model_groundTruth_dict, calculations_model_dict):\n",
    "    _calculations_metrics_dict = {}\n",
    "\n",
    "    _accuracies_list = []\n",
    "    _precisions_list = []\n",
    "    _recalls_list = []\n",
    "    _f1_scores_list = []\n",
    "\n",
    "    for key in _calculations_model_groundTruth_dict.keys():\n",
    "        _groundTruth_list = _calculations_model_groundTruth_dict[key]\n",
    "        _model_list = calculations_model_dict[key]\n",
    "\n",
    "        _calculations_metrics_dict[key] = []\n",
    "\n",
    "        for _groundTruth_dict in _groundTruth_list:\n",
    "            # 根据函数名称找到对应的模型输出\n",
    "            _func_name = _groundTruth_dict[\"Function\"]\n",
    "            for _model_dict in _model_list:\n",
    "                if _model_dict[\"Function\"] == _func_name:\n",
    "                    _metrics_dict_perFunc = calculate_metrics_fromLists(_groundTruth_dict[\"Calculation Variables\"], _model_dict[\"Full Calculation Variables\"])\n",
    "\n",
    "                    _accuracies_list.append(_metrics_dict_perFunc[\"Accuracy\"])\n",
    "                    _precisions_list.append(_metrics_dict_perFunc[\"Precision\"])\n",
    "                    _recalls_list.append(_metrics_dict_perFunc[\"Recall\"])\n",
    "                    _f1_scores_list.append(_metrics_dict_perFunc[\"F1 Score\"])\n",
    "\n",
    "                    _calculations_metrics_dict[key].append({\n",
    "                        \"Function\": _func_name,\n",
    "                        \"Metrics\": _metrics_dict_perFunc\n",
    "                    })\n",
    "\n",
    "                    break\n",
    "    \n",
    "    _avg_accuracy = np.mean(_accuracies_list)\n",
    "    _avg_precision = np.mean(_precisions_list)\n",
    "    _avg_recall = np.mean(_recalls_list)\n",
    "    _avg_f1_score = np.mean(_f1_scores_list)\n",
    "\n",
    "    _calculations_metrics_dict[\"Mean\"] = {\n",
    "        \"Accuracy\": _avg_accuracy,\n",
    "        \"Precision\": _avg_precision,\n",
    "        \"Recall\": _avg_recall,\n",
    "        \"F1 Score\": _avg_f1_score\n",
    "    }\n",
    "    \n",
    "    return _calculations_metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a8f2905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************************************************\n",
    "# DeFi Staking Defects Detection metrics\n",
    "# ************************************************************\n",
    "def get_defects_detection_metrics(_groundTruth_json_path, _defects_json_path):\n",
    "    _metrics_dict = {}\n",
    "\n",
    "    _groundTruth_dict = read_json(_groundTruth_json_path)\n",
    "    _defects_dict = read_json(_defects_json_path)\n",
    "    _defects_groundTruth_dict = _groundTruth_dict[\"Defects\"]\n",
    "\n",
    "    for key in _defects_groundTruth_dict.keys():\n",
    "        _num_defects_groundTruth = len(_defects_groundTruth_dict[key])\n",
    "        _num_defects_detected = len(_defects_dict[key])\n",
    "\n",
    "        if _num_defects_detected == 0 and _num_defects_groundTruth == 0:\n",
    "            _metrics_dict[key] = \"TN\"\n",
    "\n",
    "        if _num_defects_detected == 0 and _num_defects_groundTruth > 0:\n",
    "            _metrics_dict[key] = \"FN\"\n",
    "\n",
    "        if _num_defects_detected > 0 and _num_defects_groundTruth == 0:\n",
    "            _metrics_dict[key] = \"FP\"\n",
    "\n",
    "        if _num_defects_detected > 0 and _num_defects_groundTruth > 0:\n",
    "            _metrics_dict[key] = \"TP\"\n",
    "    \n",
    "    return _metrics_dict\n",
    "\n",
    "# ************************************************************\n",
    "# Total metrics\n",
    "# ************************************************************\n",
    "def output_total_metrics_perProject(_groundTruth_json_path, _model_json_path, _defects_json_path, output_json_path):\n",
    "    _metrics_dict = {}\n",
    "\n",
    "    _model_metrics_dict = get_model_metrics(_groundTruth_json_path, _model_json_path)\n",
    "    _defects_detection_metrics_dict = get_defects_detection_metrics(_groundTruth_json_path, _defects_json_path)\n",
    "\n",
    "    _metrics_dict[\"Model\"] = _model_metrics_dict\n",
    "    _metrics_dict[\"Defects\"] = _defects_detection_metrics_dict\n",
    "\n",
    "    # Output\n",
    "    with open(output_json_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(_metrics_dict, file, indent=4)\n",
    "    \n",
    "    return _metrics_dict\n",
    "\n",
    "# ************************************************************\n",
    "# GroundTruth Dataset metrics\n",
    "# ************************************************************\n",
    "\n",
    "# 输出groundTruth数据集中DeFi Staking建模以及漏洞检测的效果\n",
    "def output_groundTruth_metrics(_groundTruth_folder_path, _output_json_path):\n",
    "    _metrics_dict = get_groundTruth_metrics_dict(_groundTruth_folder_path)\n",
    "\n",
    "    # Output\n",
    "    with open(_output_json_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(_metrics_dict, file, indent=4)\n",
    "\n",
    "\n",
    "# 计算groundTruth数据集中DeFi Staking建模以及漏洞检测的效果\n",
    "def get_groundTruth_metrics_dict(_groundTruth_folder_path):\n",
    "    _metrics_dict_list = read_json_files_from_folder(_groundTruth_folder_path)\n",
    "\n",
    "    # _metrics_model_dict = get_total_metrics_model(_metrics_dict_list)\n",
    "    _metrics_defects_dict = get_total_metrics_defects(_metrics_dict_list)\n",
    "\n",
    "    _metrics_dict = {\n",
    "        # \"Model\": _metrics_model_dict,\n",
    "        \"Defects\": _metrics_defects_dict\n",
    "    }\n",
    "\n",
    "    return _metrics_dict\n",
    "\n",
    "# 从指定文件夹中读取所有的json文件，并生成list\n",
    "def read_json_files_from_folder(folder_path):\n",
    "    json_data_list = []\n",
    "    \n",
    "    # 遍历文件夹中的所有文件\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # 检查文件扩展名是否为.json\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # 打开并读取JSON文件\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    json_data_list.append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"文件 {filename} 不是有效的JSON文件，跳过该文件。\")\n",
    "    \n",
    "    return json_data_list\n",
    "\n",
    "\n",
    "# 计算DeFi Staking模型的总体指标\n",
    "def get_total_metrics_model(_metrics_dict_list):\n",
    "    _variables_accuracies_list = []\n",
    "    _variables_precisions_list = []\n",
    "    _variables_recalls_list = []\n",
    "    _variables_f1_scores_list = []\n",
    "\n",
    "    _functions_accuracies_list = []\n",
    "    _functions_precisions_list = []\n",
    "    _functions_recalls_list = []\n",
    "    _functions_f1_scores_list = []\n",
    "\n",
    "    _calculations_accuracies_list = []\n",
    "    _calculations_precisions_list = []\n",
    "    _calculations_recalls_list = []\n",
    "    _calculations_f1_scores_list = []\n",
    "\n",
    "    _mean_accuracies_list = []\n",
    "    _mean_precisions_list = []\n",
    "    _mean_recalls_list = []\n",
    "    _mean_f1_scores_list = []\n",
    "\n",
    "    for _metrics_dict_perProject in _metrics_dict_list:\n",
    "        _metrics_model_dict_perProject = _metrics_dict_perProject[\"Model\"]\n",
    "\n",
    "        _variables_accuracies_list.append(_metrics_model_dict_perProject[\"Variables\"][\"Mean\"][\"Accuracy\"])\n",
    "        _variables_precisions_list.append(_metrics_model_dict_perProject[\"Variables\"][\"Mean\"][\"Precision\"])\n",
    "        _variables_recalls_list.append(_metrics_model_dict_perProject[\"Variables\"][\"Mean\"][\"Recall\"])\n",
    "        _variables_f1_scores_list.append(_metrics_model_dict_perProject[\"Variables\"][\"Mean\"][\"F1 Score\"])\n",
    "\n",
    "        _functions_accuracies_list.append(_metrics_model_dict_perProject[\"Functions\"][\"Mean\"][\"Accuracy\"])\n",
    "        _functions_precisions_list.append(_metrics_model_dict_perProject[\"Functions\"][\"Mean\"][\"Precision\"])\n",
    "        _functions_recalls_list.append(_metrics_model_dict_perProject[\"Functions\"][\"Mean\"][\"Recall\"])\n",
    "        _functions_f1_scores_list.append(_metrics_model_dict_perProject[\"Functions\"][\"Mean\"][\"F1 Score\"])\n",
    "\n",
    "        _calculations_accuracies_list.append(_metrics_model_dict_perProject[\"Calculations\"][\"Mean\"][\"Accuracy\"])\n",
    "        _calculations_precisions_list.append(_metrics_model_dict_perProject[\"Calculations\"][\"Mean\"][\"Precision\"])\n",
    "        _calculations_recalls_list.append(_metrics_model_dict_perProject[\"Calculations\"][\"Mean\"][\"Recall\"])\n",
    "        _calculations_f1_scores_list.append(_metrics_model_dict_perProject[\"Calculations\"][\"Mean\"][\"F1 Score\"])\n",
    "\n",
    "        _mean_accuracies_list.append(_metrics_model_dict_perProject[\"Mean\"][\"Accuracy\"])\n",
    "        _mean_precisions_list.append(_metrics_model_dict_perProject[\"Mean\"][\"Precision\"])\n",
    "        _mean_recalls_list.append(_metrics_model_dict_perProject[\"Mean\"][\"Recall\"])\n",
    "        _mean_f1_scores_list.append(_metrics_model_dict_perProject[\"Mean\"][\"F1 Score\"])\n",
    "\n",
    "    _total_metrics_model_dict_variables = {\n",
    "        \"Accuracy\": np.mean(_variables_accuracies_list),\n",
    "        \"Precision\": np.mean(_variables_precisions_list),\n",
    "        \"Recall\": np.mean(_variables_recalls_list), \n",
    "        \"F1 Score\": np.mean(_variables_f1_scores_list)\n",
    "    }\n",
    "\n",
    "    _total_metrics_model_dict_functions = {\n",
    "        \"Accuracy\": np.mean(_functions_accuracies_list),\n",
    "        \"Precision\": np.mean(_functions_precisions_list),\n",
    "        \"Recall\": np.mean(_functions_recalls_list), \n",
    "        \"F1 Score\": np.mean(_functions_f1_scores_list)\n",
    "    }\n",
    "\n",
    "    _total_metrics_model_dict_calculations = {\n",
    "        \"Accuracy\": np.mean(_calculations_accuracies_list),\n",
    "        \"Precision\": np.mean(_calculations_precisions_list),\n",
    "        \"Recall\": np.mean(_calculations_recalls_list), \n",
    "        \"F1 Score\": np.mean(_calculations_f1_scores_list)\n",
    "    }\n",
    "\n",
    "    _total_metrics_model_dict_total = {\n",
    "        \"Accuracy\": np.mean(_mean_accuracies_list),\n",
    "        \"Precision\": np.mean(_mean_precisions_list),\n",
    "        \"Recall\": np.mean(_mean_recalls_list), \n",
    "        \"F1 Score\": np.mean(_mean_f1_scores_list)\n",
    "    }\n",
    "\n",
    "    _total_metrics_model_dict = {\n",
    "        \"Variables\": _total_metrics_model_dict_variables,\n",
    "        \"Functions\": _total_metrics_model_dict_functions,\n",
    "        \"Calculations\": _total_metrics_model_dict_calculations,\n",
    "        \"Total\": _total_metrics_model_dict_total\n",
    "    }\n",
    "\n",
    "    return _total_metrics_model_dict\n",
    "\n",
    "# 计算DeFi Staking Defects Detection的总体指标\n",
    "def get_total_metrics_defects(_metrics_dict_list):\n",
    "    # 初始化变量\n",
    "    _num_cvm_tp = 0\n",
    "    _num_cvm_fp = 0\n",
    "    _num_cvm_tn = 0\n",
    "    _num_cvm_fn = 0\n",
    "\n",
    "    _num_rt_tp = 0\n",
    "    _num_rt_fp = 0\n",
    "    _num_rt_tn = 0\n",
    "    _num_rt_fn = 0\n",
    "\n",
    "    _num_slr_tp = 0\n",
    "    _num_slr_fp = 0\n",
    "    _num_slr_tn = 0\n",
    "    _num_slr_fn = 0\n",
    "\n",
    "    _num_esu_tp = 0\n",
    "    _num_esu_fp = 0\n",
    "    _num_esu_tn = 0\n",
    "    _num_esu_fn = 0\n",
    "\n",
    "    _num_uv_tp = 0\n",
    "    _num_uv_fp = 0\n",
    "    _num_uv_tn = 0\n",
    "    _num_uv_fn = 0\n",
    "\n",
    "    _num_ufa_tp = 0\n",
    "    _num_ufa_fp = 0\n",
    "    _num_ufa_tn = 0\n",
    "    _num_ufa_fn = 0\n",
    "\n",
    "    for _metrics_dict_perProject in _metrics_dict_list:\n",
    "        _metrics_defects_dict_perProject = _metrics_dict_perProject[\"Defects\"]\n",
    "        # print(_metrics_defects_dict_perProject)\n",
    "\n",
    "        _cvm_result_perProject = _metrics_defects_dict_perProject[\"Critical Variables Manipulation (CVM)\"]\n",
    "        _rt_result_perProject = _metrics_defects_dict_perProject[\"Rewards without Timedelay (RT)\"]\n",
    "        _slr_result_perProject = _metrics_defects_dict_perProject[\"Single Liquidity Pool Reliance (SLR)\"]\n",
    "        _esu_result_perProject = _metrics_defects_dict_perProject[\"Omission in Status Update (OSU)\"]\n",
    "        _uv_result_perProject = _metrics_defects_dict_perProject[\"Unsafe Verifications (UV)\"]\n",
    "        _ufa_result_perProject = _metrics_defects_dict_perProject[\"Unauthorized User Funds Access (UFA)\"]\n",
    "\n",
    "        # CVM\n",
    "        if _cvm_result_perProject == \"TP\":\n",
    "            _num_cvm_tp += 1\n",
    "        elif _cvm_result_perProject == \"FP\":\n",
    "            _num_cvm_fp += 1\n",
    "        elif _cvm_result_perProject == \"TN\":\n",
    "            _num_cvm_tn += 1\n",
    "        elif _cvm_result_perProject == \"FN\":\n",
    "            _num_cvm_fn += 1\n",
    "        \n",
    "        # RT\n",
    "        if _rt_result_perProject == \"TP\":\n",
    "            _num_rt_tp += 1\n",
    "        elif _rt_result_perProject == \"FP\":\n",
    "            _num_rt_fp += 1\n",
    "        elif _rt_result_perProject == \"TN\":\n",
    "            _num_rt_tn += 1\n",
    "        elif _rt_result_perProject == \"FN\":\n",
    "            _num_rt_fn += 1\n",
    "        \n",
    "        # SLR\n",
    "        if _slr_result_perProject == \"TP\":\n",
    "            _num_slr_tp += 1\n",
    "        elif _slr_result_perProject == \"FP\":\n",
    "            _num_slr_fp += 1\n",
    "        elif _slr_result_perProject == \"TN\":\n",
    "            _num_slr_tn += 1\n",
    "        elif _slr_result_perProject == \"FN\":\n",
    "            _num_slr_fn += 1\n",
    "        \n",
    "        # ESU\n",
    "        if _esu_result_perProject == \"TP\":\n",
    "            _num_esu_tp += 1\n",
    "        elif _esu_result_perProject == \"FP\":\n",
    "            _num_esu_fp += 1\n",
    "        elif _esu_result_perProject == \"TN\":\n",
    "            _num_esu_tn += 1\n",
    "        elif _esu_result_perProject == \"FN\":\n",
    "            _num_esu_fn += 1\n",
    "        \n",
    "        # UV\n",
    "        if _uv_result_perProject == \"TP\":\n",
    "            _num_uv_tp += 1\n",
    "        elif _uv_result_perProject == \"FP\":\n",
    "            _num_uv_fp += 1\n",
    "        elif _uv_result_perProject == \"TN\":\n",
    "            _num_uv_tn += 1\n",
    "        elif _uv_result_perProject == \"FN\":\n",
    "            _num_uv_fn += 1\n",
    "        \n",
    "        # UFA\n",
    "        if _ufa_result_perProject == \"TP\":\n",
    "            _num_ufa_tp += 1\n",
    "        elif _ufa_result_perProject == \"FP\":\n",
    "            _num_ufa_fp += 1\n",
    "        elif _ufa_result_perProject == \"TN\":\n",
    "            _num_ufa_tn += 1\n",
    "        elif _ufa_result_perProject == \"FN\":\n",
    "            _num_ufa_fn += 1\n",
    "\n",
    "    _cvm_accuracy = (_num_cvm_tp + _num_cvm_tn) / (_num_cvm_tp + _num_cvm_tn + _num_cvm_fp + _num_cvm_fn) if _num_cvm_tp + _num_cvm_tn + _num_cvm_fp + _num_cvm_fn > 0 else 0\n",
    "    _cvm_precision = _num_cvm_tp / (_num_cvm_tp + _num_cvm_fp) if _num_cvm_tp + _num_cvm_fp > 0 else 0\n",
    "    _cvm_recall = _num_cvm_tp / (_num_cvm_tp + _num_cvm_fn) if _num_cvm_tp + _num_cvm_fn > 0 else 0\n",
    "    _cvm_f1_score = 2 * _cvm_precision * _cvm_recall / (_cvm_precision + _cvm_recall) if _cvm_precision + _cvm_recall > 0 else 0\n",
    "\n",
    "    _rt_accuracy = (_num_rt_tp + _num_rt_tn) / (_num_rt_tp + _num_rt_tn + _num_rt_fp + _num_rt_fn) if _num_rt_tp + _num_rt_tn + _num_rt_fp + _num_rt_fn > 0 else 0\n",
    "    _rt_precision = _num_rt_tp / (_num_rt_tp + _num_rt_fp) if _num_rt_tp + _num_rt_fp > 0 else 0\n",
    "    _rt_recall = _num_rt_tp / (_num_rt_tp + _num_rt_fn) if _num_rt_tp + _num_rt_fn > 0 else 0\n",
    "    _rt_f1_score = 2 * _rt_precision * _rt_recall / (_rt_precision + _rt_recall) if _rt_precision + _rt_recall > 0 else 0\n",
    "\n",
    "    _slr_accuracy = (_num_slr_tp + _num_slr_tn) / (_num_slr_tp + _num_slr_tn + _num_slr_fp + _num_slr_fn) if _num_slr_tp + _num_slr_tn + _num_slr_fp + _num_slr_fn > 0 else 0\n",
    "    _slr_precision = _num_slr_tp / (_num_slr_tp + _num_slr_fp) if _num_slr_tp + _num_slr_fp > 0 else 0\n",
    "    _slr_recall = _num_slr_tp / (_num_slr_tp + _num_slr_fn) if _num_slr_tp + _num_slr_fn > 0 else 0\n",
    "    _slr_f1_score = 2 * _slr_precision * _slr_recall / (_slr_precision + _slr_recall) if _slr_precision + _slr_recall > 0 else 0\n",
    "\n",
    "    _esu_accuracy = (_num_esu_tp + _num_esu_tn) / (_num_esu_tp + _num_esu_tn + _num_esu_fp + _num_esu_fn) if _num_esu_tp + _num_esu_tn + _num_esu_fp + _num_esu_fn > 0 else 0\n",
    "    _esu_precision = _num_esu_tp / (_num_esu_tp + _num_esu_fp) if _num_esu_tp + _num_esu_fp > 0 else 0\n",
    "    _esu_recall = _num_esu_tp / (_num_esu_tp + _num_esu_fn) if _num_esu_tp + _num_esu_fn > 0 else 0\n",
    "    _esu_f1_score = 2 * _esu_precision * _esu_recall / (_esu_precision + _esu_recall) if _esu_precision + _esu_recall > 0 else 0\n",
    "\n",
    "    _uv_accuracy = (_num_uv_tp + _num_uv_tn) / (_num_uv_tp + _num_uv_tn + _num_uv_fp + _num_uv_fn) if _num_uv_tp + _num_uv_tn + _num_uv_fp + _num_uv_fn > 0 else 0\n",
    "    _uv_precision = _num_uv_tp / (_num_uv_tp + _num_uv_fp) if _num_uv_tp + _num_uv_fp > 0 else 0\n",
    "    _uv_recall = _num_uv_tp / (_num_uv_tp + _num_uv_fn) if _num_uv_tp + _num_uv_fn > 0 else 0\n",
    "    _uv_f1_score = 2 * _uv_precision * _uv_recall / (_uv_precision + _uv_recall) if _uv_precision + _uv_recall > 0 else 0\n",
    "\n",
    "    _ufa_accuracy = (_num_ufa_tp + _num_ufa_tn) / (_num_ufa_tp + _num_ufa_tn + _num_ufa_fp + _num_ufa_fn) if _num_ufa_tp + _num_ufa_tn + _num_ufa_fp + _num_ufa_fn > 0 else 0\n",
    "    _ufa_precision = _num_ufa_tp / (_num_ufa_tp + _num_ufa_fp) if _num_ufa_tp + _num_ufa_fp > 0 else 0\n",
    "    _ufa_recall = _num_ufa_tp / (_num_ufa_tp + _num_ufa_fn) if _num_ufa_tp + _num_ufa_fn > 0 else 0\n",
    "    _ufa_f1_score = 2 * _ufa_precision * _ufa_recall / (_ufa_precision + _ufa_recall) if _ufa_precision + _ufa_recall > 0 else 0\n",
    "        \n",
    "    _CVM_metrics_dict = {\n",
    "        \"TP\": _num_cvm_tp,\n",
    "        \"FP\": _num_cvm_fp,\n",
    "        \"TN\": _num_cvm_tn,\n",
    "        \"FN\": _num_cvm_fn,\n",
    "        \"Accuracy\": _cvm_accuracy,\n",
    "        \"Precision\": _cvm_precision,\n",
    "        \"Recall\": _cvm_recall,\n",
    "        \"F1 Score\": _cvm_f1_score\n",
    "    }\n",
    "\n",
    "    _RT_metrics_dict = {\n",
    "        \"TP\": _num_rt_tp,\n",
    "        \"FP\": _num_rt_fp,\n",
    "        \"TN\": _num_rt_tn,\n",
    "        \"FN\": _num_rt_fn,\n",
    "        \"Accuracy\": _rt_accuracy,\n",
    "        \"Precision\": _rt_precision,\n",
    "        \"Recall\": _rt_recall,\n",
    "        \"F1 Score\": _rt_f1_score\n",
    "    }\n",
    "\n",
    "    _SLR_metrics_dict = {\n",
    "        \"TP\": _num_slr_tp,\n",
    "        \"FP\": _num_slr_fp,\n",
    "        \"TN\": _num_slr_tn,\n",
    "        \"FN\": _num_slr_fn,\n",
    "        \"Accuracy\": _slr_accuracy,\n",
    "        \"Precision\": _slr_precision,\n",
    "        \"Recall\": _slr_recall,\n",
    "        \"F1 Score\": _slr_f1_score\n",
    "    }\n",
    "\n",
    "    _ESU_metrics_dict = {\n",
    "        \"TP\": _num_esu_tp,\n",
    "        \"FP\": _num_esu_fp,\n",
    "        \"TN\": _num_esu_tn,\n",
    "        \"FN\": _num_esu_fn,\n",
    "        \"Accuracy\": _esu_accuracy,\n",
    "        \"Precision\": _esu_precision,\n",
    "        \"Recall\": _esu_recall,\n",
    "        \"F1 Score\": _esu_f1_score\n",
    "    }\n",
    "\n",
    "    _UV_metrics_dict = {\n",
    "        \"TP\": _num_uv_tp,\n",
    "        \"FP\": _num_uv_fp,\n",
    "        \"TN\": _num_uv_tn,\n",
    "        \"FN\": _num_uv_fn,\n",
    "        \"Accuracy\": _uv_accuracy,\n",
    "        \"Precision\": _uv_precision,\n",
    "        \"Recall\": _uv_recall,\n",
    "        \"F1 Score\": _uv_f1_score\n",
    "    }\n",
    "\n",
    "    _UFA_metrics_dict = {\n",
    "        \"TP\": _num_ufa_tp,\n",
    "        \"FP\": _num_ufa_fp,\n",
    "        \"TN\": _num_ufa_tn,\n",
    "        \"FN\": _num_ufa_fn,\n",
    "        \"Accuracy\": _ufa_accuracy,\n",
    "        \"Precision\": _ufa_precision,\n",
    "        \"Recall\": _ufa_recall,\n",
    "        \"F1 Score\": _ufa_f1_score\n",
    "    }\n",
    "\n",
    "    _num_positive_cvm = _num_cvm_tp + _num_cvm_fp\n",
    "    _num_positive_rt = _num_rt_tp + _num_rt_fp\n",
    "    _num_positive_slr = _num_slr_tp + _num_slr_fp\n",
    "    _num_positive_esu = _num_esu_tp + _num_esu_fp\n",
    "    _num_positive_uv = _num_uv_tp + _num_uv_fp\n",
    "    _num_positive_ufa = _num_ufa_tp + _num_ufa_fp\n",
    "    _num_positive_total = _num_positive_cvm + _num_positive_rt + _num_positive_slr + _num_positive_esu + _num_positive_uv + _num_positive_ufa\n",
    "\n",
    "    _total_accuracy = (\n",
    "        (_CVM_metrics_dict[\"Accuracy\"] * _num_positive_cvm) + \n",
    "        (_RT_metrics_dict[\"Accuracy\"] * _num_positive_rt) + \n",
    "        (_SLR_metrics_dict[\"Accuracy\"] * _num_positive_slr) + \n",
    "        (_ESU_metrics_dict[\"Accuracy\"] * _num_positive_esu) + \n",
    "        (_UV_metrics_dict[\"Accuracy\"] * _num_positive_uv) + \n",
    "        (_UFA_metrics_dict[\"Accuracy\"] * _num_positive_ufa)\n",
    "    ) / _num_positive_total if _num_positive_total > 0 else 0\n",
    "\n",
    "    _total_precision = (\n",
    "        (_CVM_metrics_dict[\"Precision\"] * _num_positive_cvm) + \n",
    "        (_RT_metrics_dict[\"Precision\"] * _num_positive_rt) +    \n",
    "        (_SLR_metrics_dict[\"Precision\"] * _num_positive_slr) + \n",
    "        (_ESU_metrics_dict[\"Precision\"] * _num_positive_esu) + \n",
    "        (_UV_metrics_dict[\"Precision\"] * _num_positive_uv) + \n",
    "        (_UFA_metrics_dict[\"Precision\"] * _num_positive_ufa)\n",
    "    ) / _num_positive_total if _num_positive_total > 0 else 0\n",
    "\n",
    "    _total_recall = (\n",
    "        (_CVM_metrics_dict[\"Recall\"] * _num_positive_cvm) + \n",
    "        (_RT_metrics_dict[\"Recall\"] * _num_positive_rt) + \n",
    "        (_SLR_metrics_dict[\"Recall\"] * _num_positive_slr) + \n",
    "        (_ESU_metrics_dict[\"Recall\"] * _num_positive_esu) + \n",
    "        (_UV_metrics_dict[\"Recall\"] * _num_positive_uv) + \n",
    "        (_UFA_metrics_dict[\"Recall\"] * _num_positive_ufa)\n",
    "    ) / _num_positive_total if _num_positive_total > 0 else 0\n",
    "\n",
    "    _total_f1_score = (\n",
    "        (_CVM_metrics_dict[\"F1 Score\"] * _num_positive_cvm) + \n",
    "        (_RT_metrics_dict[\"F1 Score\"] * _num_positive_rt) + \n",
    "        (_SLR_metrics_dict[\"F1 Score\"] * _num_positive_slr) + \n",
    "        (_ESU_metrics_dict[\"F1 Score\"] * _num_positive_esu) + \n",
    "        (_UV_metrics_dict[\"F1 Score\"] * _num_positive_uv) + \n",
    "        (_UFA_metrics_dict[\"F1 Score\"] * _num_positive_ufa)\n",
    "    ) / _num_positive_total if _num_positive_total > 0 else 0\n",
    "\n",
    "    _total_metrics_dict = {\n",
    "        \"Accuracy\": _total_accuracy,\n",
    "        \"Precision\": _total_precision,\n",
    "        \"Recall\": _total_recall,\n",
    "        \"F1 Score\": _total_f1_score\n",
    "    }\n",
    "\n",
    "    _total_metrics_defects_dict = {\n",
    "        \"Critical Variables Manipulation (CVM)\": _CVM_metrics_dict,\n",
    "        \"Rewards without Timedelay (RT)\": _RT_metrics_dict,\n",
    "        \"Single Liquidity Pool Reliance (SLR)\": _SLR_metrics_dict,\n",
    "        \"Omission in Status Update (OSU)\": _ESU_metrics_dict,\n",
    "        \"Unsafe Verifications (UV)\": _UV_metrics_dict,\n",
    "        \"Unauthorized User Funds Access (UFA)\": _UFA_metrics_dict,\n",
    "        \"Total\": _total_metrics_dict\n",
    "    }\n",
    "\n",
    "    return _total_metrics_defects_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c2ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_all_metrics_groundTruth(_groundTruth_folder_path, _model_folder_path, _defects_folder_path, _output_json_path):\n",
    "    _metrics_dict_list = []\n",
    "    project_name_list = get_projectNams_from_folder(_groundTruth_folder_path)\n",
    "    for project_name in project_name_list:\n",
    "        # print(\"Project Name: \", project_name)\n",
    "        # 读取groundTruth.json文件\n",
    "        _groundTruth_json_path = os.path.join(_groundTruth_folder_path, project_name + \".json\")\n",
    "        _defects_json_path = os.path.join(_defects_folder_path, project_name + \".json\")\n",
    "        _model_json_path = os.path.join(_model_folder_path, project_name + \".json\")\n",
    "\n",
    "        _metrics_dict = {}\n",
    "\n",
    "        _model_metrics_dict = get_model_metrics(_groundTruth_json_path, _model_json_path)\n",
    "        _defects_detection_metrics_dict = get_defects_detection_metrics(_groundTruth_json_path, _defects_json_path)\n",
    "\n",
    "        _metrics_dict[\"Model\"] = _model_metrics_dict\n",
    "        _metrics_dict[\"Defects\"] = _defects_detection_metrics_dict\n",
    "\n",
    "        _metrics_dict_list.append(_metrics_dict)\n",
    "\n",
    "    _total_metrics_defects_dict = get_total_metrics_defects(_metrics_dict_list)\n",
    "    _total_metrics_model_dict = get_total_metrics_model(_metrics_dict_list)\n",
    "\n",
    "    _metrics_dict = {\n",
    "        \"Model\": _total_metrics_model_dict,\n",
    "        \"Defects\": _total_metrics_defects_dict\n",
    "    }\n",
    "\n",
    "    # Output\n",
    "    with open(_output_json_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(_metrics_dict, file, indent=4)\n",
    "\n",
    "    return _metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d4c13f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "groungTruth_folder_path = \"/mnt/linzw3/work/defistaking/3_Experiment/groundTruth/1_groundTruth\"\n",
    "defects_folder_path = \"/mnt/linzw3/work/defistaking/3_Experiment/groundTruth/3_defects/defects\"\n",
    "model_folder_path = \"/mnt/linzw3/work/defistaking/3_Experiment/groundTruth/2_model/model\"\n",
    "output_json_path = \"/mnt/linzw3/work/defistaking/3_Experiment/groundTruth/4_metrics/groundTruth_metrics.json\"\n",
    "\n",
    "total_groundTruth_metrics_dict = output_all_metrics_groundTruth(groungTruth_folder_path, model_folder_path, defects_folder_path, output_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd07743c",
   "metadata": {},
   "source": [
    "largeScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb9bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有链的检测结果所在的文件夹\n",
    "path_largeScale_results = \"/mnt/linzw3/work/defistaking/3_Experiment/largeScale/2_defects\"\n",
    "path_largeScale_dataset = \"/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final\"\n",
    "path_largeScale_infos = \"/mnt/linzw3/work/defistaking/3_Experiment/largeScale/1_model/infos\"\n",
    "path_largeScale_model = \"/mnt/linzw3/work/defistaking/3_Experiment/largeScale/1_model/model\"\n",
    "\n",
    "# 所有链的名称\n",
    "chain_list = [\n",
    "    \"ethereum\",\n",
    "    \"bsc\",\n",
    "    \"arbitrum\",\n",
    "    \"avalanche\",\n",
    "    \"celo\",\n",
    "    \"fantom\",\n",
    "    \"optimism\",\n",
    "    \"polygon\",\n",
    "    \"tron\"\n",
    "]\n",
    "\n",
    "defects_kind_list = [\n",
    "    \"Critical Variables Manipulation (CVM)\",\n",
    "    \"Rewards without Timedelay (RT)\",\n",
    "    \"Single Liquidity Pool Reliance (SLR)\",\n",
    "    \"Omission in Status Update (OSU)\",\n",
    "    \"Unsafe Verifications (UV)\",\n",
    "    \"Unauthorized User Funds Access (UFA)\"\n",
    "]\n",
    "\n",
    "list_largeScale_results_path = [path_largeScale_results + \"/\" + chain_name for chain_name in chain_list] \n",
    "list_largeScale_defects_path = [list_largeScale_results_path[i] + \"/defects\" for i in range(len(chain_list))]\n",
    "list_largeScale_details_path = [list_largeScale_results_path[i] + \"/details\" for i in range(len(chain_list))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a278ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying .sol files for ethereum\n",
      "文件夹 C (/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final_2/ethereum) 不存在，已创建该文件夹。\n",
      "Copying .sol files for bsc\n",
      "文件夹 C (/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final_2/bsc) 不存在，已创建该文件夹。\n",
      "在文件夹 B 中找不到匹配的 .sol 文件: A61C3c7B1297fF1e26D0f56DFBD518a1078e791c_MasterChef.sol\n",
      "Copying .sol files for arbitrum\n",
      "文件夹 C (/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final_2/arbitrum) 不存在，已创建该文件夹。\n",
      "Copying .sol files for avalanche\n",
      "文件夹 C (/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final_2/avalanche) 不存在，已创建该文件夹。\n",
      "Copying .sol files for celo\n",
      "文件夹 C (/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final_2/celo) 不存在，已创建该文件夹。\n",
      "Copying .sol files for fantom\n",
      "文件夹 C (/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final_2/fantom) 不存在，已创建该文件夹。\n",
      "Copying .sol files for optimism\n",
      "文件夹 C (/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final_2/optimism) 不存在，已创建该文件夹。\n",
      "Copying .sol files for polygon\n",
      "文件夹 C (/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final_2/polygon) 不存在，已创建该文件夹。\n",
      "Copying .sol files for tron\n",
      "文件夹 C (/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final_2/tron) 不存在，已创建该文件夹。\n"
     ]
    }
   ],
   "source": [
    "# 复制数据集，不用再跑了\n",
    "def copy_matching_sol_files(folder_defects, folder_dataset_origin, folder_dataset_final):\n",
    "    # 如果文件夹 folder_dataset_final 不存在，则创建它\n",
    "    if not os.path.exists(folder_dataset_final):\n",
    "        os.makedirs(folder_dataset_final)\n",
    "        print(f\"文件夹 C ({folder_dataset_final}) 不存在，已创建该文件夹。\")\n",
    "\n",
    "    # 遍历文件夹 A 中的每个 JSON 文件\n",
    "    for json_filename in os.listdir(folder_defects):\n",
    "        if json_filename.endswith('.json'):\n",
    "            # 获取文件名（不带扩展名）\n",
    "            json_basename = os.path.splitext(json_filename)[0]\n",
    "            sol_filename = f\"{json_basename}.sol\"\n",
    "            sol_path = os.path.join(folder_dataset_origin, sol_filename)\n",
    "\n",
    "            # 检查对应的 .sol 文件是否存在于文件夹 B 中\n",
    "            if os.path.isfile(sol_path):\n",
    "                # 构造目标路径\n",
    "                target_path = os.path.join(folder_dataset_final, sol_filename)\n",
    "                # 执行复制操作\n",
    "                shutil.copy(sol_path, target_path)\n",
    "                # print(f\"已将 {sol_filename} 从 {folder_dataset_origin} 复制到 {folder_dataset_final}\")\n",
    "            else:\n",
    "                print(f\"在文件夹 B 中找不到匹配的 .sol 文件: {sol_filename}\")\n",
    "\n",
    "folder_infos_all = \"/mnt/linzw3/work/defistaking/3_Experiment/largeScale/1_model/infos\"\n",
    "folder_dataset_origin_all = \"/mnt/linzw3/work/defistaking/1_Datasets/largeScale/analyzable\"\n",
    "folder_dataset_final_all = \"/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final_2\"\n",
    "\n",
    "for chain_name in chain_list:\n",
    "    print(\"Copying .sol files for \" + chain_name)\n",
    "    path_folder_infos = folder_infos_all + \"/\" + chain_name \n",
    "    path_folder_dataset_origin = folder_dataset_origin_all + \"/\" + chain_name\n",
    "    path_folder_dataset_final = folder_dataset_final_all + \"/\" + chain_name\n",
    "    copy_matching_sol_files(path_folder_infos, path_folder_dataset_origin, path_folder_dataset_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d13fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final_2/bsc/A61C3c7B1297fF1e26D0f56DFBD518a1078e791c_MasterChef.sol'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_file_path = '/mnt/linzw3/work/defistaking/1_Datasets/largeScale/bsc/A61C3c7B1297fF1e26D0f56DFBD518a1078e791c_MasterChef.sol'\n",
    "\n",
    "file_name = os.path.basename(missed_file_path)\n",
    "destination_path = path_largeScale_dataset + '/bsc/' + file_name\n",
    "\n",
    "shutil.copy(missed_file_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed02b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "智能合约源码(sol)文件夹:\n",
      "ethereum: 1097 个文件\n",
      "bsc: 5718 个文件\n",
      "arbitrum: 748 个文件\n",
      "avalanche: 1386 个文件\n",
      "celo: 28 个文件\n",
      "fantom: 2335 个文件\n",
      "optimism: 92 个文件\n",
      "polygon: 3917 个文件\n",
      "tron: 671 个文件\n",
      "总数量: 15992 个文件\n",
      "\n",
      "合约基本信息(json)文件夹:\n",
      "bsc: 5718 个文件\n",
      "arbitrum: 748 个文件\n",
      "avalanche: 1386 个文件\n",
      "celo: 28 个文件\n",
      "fantom: 2335 个文件\n",
      "optimism: 92 个文件\n",
      "polygon: 3917 个文件\n",
      "tron: 671 个文件\n",
      "ethereum: 1097 个文件\n",
      "总数量: 15992 个文件\n",
      "\n",
      "合约建模(json)文件夹:\n",
      "bsc: 5607 个文件\n",
      "arbitrum: 741 个文件\n",
      "avalanche: 1385 个文件\n",
      "celo: 28 个文件\n",
      "fantom: 2312 个文件\n",
      "optimism: 92 个文件\n",
      "polygon: 3899 个文件\n",
      "tron: 666 个文件\n",
      "ethereum: 1086 个文件\n",
      "总数量: 15816 个文件\n"
     ]
    }
   ],
   "source": [
    "# 验证大规模数据\n",
    "def count_files_in_subfolders(folder_path):\n",
    "    \"\"\"计算每个子文件夹中文件的数量，并返回总数量\"\"\"\n",
    "    total_files = 0\n",
    "    subfolder_counts = {}\n",
    "\n",
    "    for subfolder in os.listdir(folder_path):\n",
    "        subfolder_path = os.path.join(folder_path, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            files = os.listdir(subfolder_path)\n",
    "            subfolder_counts[subfolder] = len(files)\n",
    "            total_files += len(files)\n",
    "    \n",
    "    return subfolder_counts, total_files\n",
    "\n",
    "# 获取每个文件夹的文件数量和总数量\n",
    "sol_counts, sol_total = count_files_in_subfolders(path_largeScale_dataset)\n",
    "txt_counts, txt_total = count_files_in_subfolders(path_largeScale_infos)\n",
    "json_counts, json_total = count_files_in_subfolders(path_largeScale_model)\n",
    "\n",
    "# 输出每个子文件夹中文件数量\n",
    "print(\"智能合约源码(sol)文件夹:\")\n",
    "for subfolder, count in sol_counts.items():\n",
    "    print(f\"{subfolder}: {count} 个文件\")\n",
    "print(f\"总数量: {sol_total} 个文件\")\n",
    "\n",
    "print(\"\\n合约基本信息(json)文件夹:\")\n",
    "for subfolder, count in txt_counts.items():\n",
    "    print(f\"{subfolder}: {count} 个文件\")\n",
    "print(f\"总数量: {txt_total} 个文件\")\n",
    "\n",
    "print(\"\\n合约建模(json)文件夹:\")\n",
    "for subfolder, count in json_counts.items():\n",
    "    print(f\"{subfolder}: {count} 个文件\")\n",
    "print(f\"总数量: {json_total} 个文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d7b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_defects_results_allChains(_chain_list, _path_largeScale_dataset, _path_largeScale_results):\n",
    "    # 初始化检测结果：DataFrame结构\n",
    "    # 创建列名，\"Contract\" 作为第一列，其余来自输入列表\n",
    "    all_columns = [\"Contract\"] + defects_kind_list\n",
    "    # 构建空的 DataFrame，只有列名，没有数据\n",
    "    df_defects_all = pd.DataFrame(columns = all_columns)\n",
    "\n",
    "    for _chain_name in _chain_list:\n",
    "        # 读取某个链上所有合约的检测结果\n",
    "        _path_dataset_perChain = _path_largeScale_dataset + \"/\" + _chain_name\n",
    "        _path_defects_perChain = _path_largeScale_results + \"/\" + _chain_name + \"/defects\"\n",
    "        df_defects_perChain = read_defects_results_perChain(_path_dataset_perChain, _path_defects_perChain)\n",
    "        # 合并两个 DataFrame\n",
    "        df_combined = pd.concat([df_defects_all, df_defects_perChain], ignore_index=True)\n",
    "        df_defects_all = df_combined\n",
    "\n",
    "    return df_defects_all\n",
    "\n",
    "\n",
    "# 读取所有链上合约的检测结果（只保留是否存在缺陷）\n",
    "def read_defects_results_perChain(_path_dataset_perChain, _path_largeScale_defects_perChain):\n",
    "    # 初始化检测结果：DataFrame结构\n",
    "    # 创建列名，\"Contract\" 作为第一列，其余来自输入列表\n",
    "    all_columns = [\"Contract\"] + defects_kind_list\n",
    "    \n",
    "    # 构建空的 DataFrame，只有列名，没有数据\n",
    "    df_defects = pd.DataFrame(columns = all_columns)\n",
    "    \n",
    "    # 读取所有\n",
    "    list_solPaths = get_solPath_list(_path_dataset_perChain)\n",
    "    for _sol_path in list_solPaths:\n",
    "        # 读取合约名\n",
    "        contract_name = os.path.basename(_sol_path)[:-4]  # 去掉.sol 后缀\n",
    "        _json_path = os.path.join(_path_largeScale_defects_perChain, contract_name + \".json\")\n",
    "\n",
    "        if not os.path.exists(_json_path):\n",
    "            _dict_defects_perContract = {\"Contract\": _sol_path}  # 合约名作为第一列\n",
    "            for _defect_kind in defects_kind_list:\n",
    "                _dict_defects_perContract[_defect_kind] = False  # 缺陷类型列初始化为 False\n",
    "            new_row = pd.DataFrame([_dict_defects_perContract])\n",
    "            df_defects = pd.concat([df_defects, new_row], ignore_index=True)\n",
    "            continue\n",
    "\n",
    "        _dict_defects_perContract = read_defects_results_perContract(_json_path)\n",
    "        _dict_defects_perContract[\"Contract\"] = _sol_path  # 合约名作为第一列\n",
    "\n",
    "        # 将新的一行添加到DataFrame\n",
    "        new_row = pd.DataFrame([_dict_defects_perContract])\n",
    "        df_defects = pd.concat([df_defects, new_row], ignore_index=True)\n",
    "\n",
    "    # 输出dataFrame\n",
    "    return df_defects\n",
    "\n",
    "# 读取某个合约的检测结果\n",
    "def read_defects_results_perContract(_path_json_file):\n",
    "    # 读取 JSON 文件\n",
    "    with open(_path_json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 创建一个新的行数据字典\n",
    "    dict_results_perContract = {}  # \"Contract\"列为json文件路径\n",
    "    \n",
    "    # 遍历除“Contract”外的列名\n",
    "    for key, value in data.items():\n",
    "        dict_results_perContract[key] = True if len(value) > 0 else False\n",
    "    \n",
    "    return dict_results_perContract\n",
    "\n",
    "# 获取指定文件夹中所有json文件的路径\n",
    "def get_jsonPath_list(folder_path):\n",
    "    # 存储所有json文件路径的列表\n",
    "    list_json_path = []\n",
    "    \n",
    "    # 遍历文件夹\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):  # 判断文件扩展名是否为.json\n",
    "                list_json_path.append(os.path.join(root, file))  # 获取文件的完整路径并添加到列表\n",
    "\n",
    "    return list_json_path\n",
    "\n",
    "# 获取指定文件夹中所有json文件的路径\n",
    "def get_solPath_list(folder_path):\n",
    "    # 存储所有json文件路径的列表\n",
    "    list_sol_path = []\n",
    "    \n",
    "    # 遍历文件夹\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".sol\"):  # 判断文件扩展名是否为.sol\n",
    "                list_sol_path.append(os.path.join(root, file))  # 获取文件的完整路径并添加到列表\n",
    "\n",
    "    return list_sol_path\n",
    "\n",
    "def analyze_vulnerabilities(df):\n",
    "    # 假设第一列是文件路径，后6列是漏洞标志（True/False）\n",
    "    vuln_columns = df.columns[1:]  # A-F\n",
    "    total_files = len(df)\n",
    "\n",
    "    print(f\"总文件数量: {total_files}\")\n",
    "\n",
    "    print(\"各漏洞类型的文件数量及比例：\\n\")\n",
    "    for col in vuln_columns:\n",
    "        count = df[col].sum()  # True 会被当作 1 来统计\n",
    "        ratio = count / total_files\n",
    "        print(f\"{col} 漏洞: 数量 = {count}, 比例 = {ratio:.2%}\")\n",
    "\n",
    "    # 至少包含一种漏洞的文件数量和比例\n",
    "    any_vuln_mask = df[vuln_columns].sum(axis=1) > 0\n",
    "    any_vuln_count = any_vuln_mask.sum()\n",
    "    any_vuln_ratio = any_vuln_count / total_files\n",
    "\n",
    "    print(\"\\n至少包含一种漏洞的文件：\")\n",
    "    print(f\"数量 = {any_vuln_count}, 比例 = {any_vuln_ratio:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72a430ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总文件数量: 15992\n",
      "各漏洞类型的文件数量及比例：\n",
      "\n",
      "Critical Variables Manipulation (CVM) 漏洞: 数量 = 430, 比例 = 2.69%\n",
      "Rewards without Timedelay (RT) 漏洞: 数量 = 516, 比例 = 3.23%\n",
      "Single Liquidity Pool Reliance (SLR) 漏洞: 数量 = 44, 比例 = 0.28%\n",
      "Omission in Status Update (OSU) 漏洞: 数量 = 889, 比例 = 5.56%\n",
      "Unsafe Verifications (UV) 漏洞: 数量 = 1315, 比例 = 8.22%\n",
      "Unauthorized User Funds Access (UFA) 漏洞: 数量 = 846, 比例 = 5.29%\n",
      "\n",
      "至少包含一种漏洞的文件：\n",
      "数量 = 3557, 比例 = 22.24%\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "df_defects_allChains = read_defects_results_allChains(chain_list, path_largeScale_dataset, path_largeScale_results)\n",
    "analyze_vulnerabilities(df_defects_allChains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "252f6de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final/ethereum/B6e576f7dEeDdb8cF941625C2b7C78472F162553_StakingETH.sol'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_defects_allChains[\"Contract\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1505c1d9",
   "metadata": {},
   "source": [
    "随机抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510a4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(N, confidence_level=0.95, margin_error=0.10):\n",
    "    \"\"\"\n",
    "    使用简单的二项分布估算样本量。\n",
    "    Z值约为1.96（对应95%置信度）\n",
    "    \"\"\"\n",
    "    Z = 1.96\n",
    "    p = 0.5  # 最保守估计\n",
    "    e = margin_error\n",
    "    n_0 = (Z**2 * p * (1 - p)) / (e**2)\n",
    "    n = n_0 / (1 + (n_0 - 1) / N)\n",
    "    return min(N, math.ceil(n))\n",
    "\n",
    "def generate_paths(contract_path_str):\n",
    "    contract_path = Path(contract_path_str)\n",
    "    largeScale_dataset_folder = Path(\"/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final\")\n",
    "    largeScale_results_folder = Path(\"/mnt/linzw3/work/defistaking/3_Experiment/largeScale/2_defects\")\n",
    "\n",
    "    # 拆解路径：.../blockchain_name/defects/contract.json\n",
    "\n",
    "    blockchain_name = contract_path.parts[-2]         # 区块链名称\n",
    "    contract_name = contract_path.stem.split(\".\")[0]  # 合约名（不含后缀）\n",
    "\n",
    "    # 构造新的路径\n",
    "    defect_path = largeScale_results_folder / blockchain_name / \"defects\" / f\"{contract_name}.json\"\n",
    "    detail_path = largeScale_results_folder / blockchain_name / \"details\" / f\"{contract_name}.txt\"\n",
    "    source_path = largeScale_dataset_folder / blockchain_name / f\"{contract_name}.sol\"\n",
    "    contract_infos = blockchain_name + \"/\" + contract_name\n",
    "\n",
    "    return str(defect_path), str(detail_path), str(source_path), contract_infos\n",
    "\n",
    "def sample_and_copy(df_defects_all: pd.DataFrame, vuln_col: str, base_output_dir: str):\n",
    "    # 过滤出该漏洞为True的行\n",
    "    vuln_true_df = df_defects_all[df_defects_all[vuln_col] == True]\n",
    "\n",
    "    N = len(vuln_true_df)\n",
    "    if N == 0:\n",
    "        print(f\"[警告] 漏洞 {vuln_col} 无任何 True 样本，跳过。\")\n",
    "        return\n",
    "\n",
    "    sample_size = calculate_sample_size(N)\n",
    "    print(f\"[信息] {vuln_col} 样本量为 {sample_size}\")\n",
    "    sampled_df = vuln_true_df.sample(n=sample_size, random_state=314)\n",
    "\n",
    "    # 创建子文件夹\n",
    "    vuln_folder = Path(base_output_dir) / vuln_col\n",
    "    vuln_folder.mkdir(parents=True, exist_ok=True)\n",
    "    vuln_contract_folder = vuln_folder / \"contract\"\n",
    "    vuln_contract_folder.mkdir(parents=True, exist_ok=True)\n",
    "    vuln_details_folder = vuln_folder / \"details\"\n",
    "    vuln_details_folder.mkdir(parents=True, exist_ok=True)\n",
    "    vuln_defects_folder = vuln_folder / \"defects\"\n",
    "    vuln_defects_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    sampled_paths = []\n",
    "\n",
    "    for contract_sol_path in sampled_df.iloc[:, 0]:\n",
    "        defect_json_path, detail_txt_path, contract_path, contract_infos = generate_paths(contract_sol_path)\n",
    "        contract_path = Path(contract_path)\n",
    "        detail_txt_path = Path(detail_txt_path)\n",
    "        defect_json_path = Path(defect_json_path)\n",
    "\n",
    "        if contract_path.exists():\n",
    "            dest_path = vuln_folder / \"contract\" / contract_path.name\n",
    "            shutil.copy(contract_path, dest_path)\n",
    "        else:\n",
    "            print(f\"[警告] 找不到文件: {contract_path}\")\n",
    "\n",
    "        if detail_txt_path.exists():\n",
    "            dest_path = vuln_folder / \"details\" / detail_txt_path.name\n",
    "            shutil.copy(detail_txt_path, dest_path)\n",
    "        else:\n",
    "            print(f\"[警告] 找不到文件: {detail_txt_path}\")\n",
    "\n",
    "        if defect_json_path.exists():\n",
    "            dest_path = vuln_folder / \"defects\" / defect_json_path.name\n",
    "            shutil.copy(defect_json_path, dest_path)\n",
    "        else:\n",
    "            print(f\"[警告] 找不到文件: {defect_json_path}\")\n",
    "\n",
    "        sampled_paths.append(str(contract_infos))\n",
    "\n",
    "    # 保存抽样路径到Excel\n",
    "    result_df = pd.DataFrame(sampled_paths, columns=[\"ContractPath\"])\n",
    "    excel_path = Path(base_output_dir) / f\"{vuln_col}_sampled.xlsx\"\n",
    "    result_df.to_excel(excel_path, index=False)\n",
    "    print(f\"[信息] 已完成 {vuln_col} 抽样并保存至 {excel_path}\")\n",
    "\n",
    "def output_sampled_contracts(df_defects, output_folder: str):\n",
    "    if df_defects.shape[1] < 7:\n",
    "        print(\"[错误] 输入数据列数不足，应包含至少7列（路径 + 6种漏洞标志）\")\n",
    "        return\n",
    "\n",
    "    # 提取漏洞列名（假设从第2列到第7列）\n",
    "    vuln_columns = df_defects.columns[1:7]\n",
    "\n",
    "    for vuln in vuln_columns:\n",
    "        sample_and_copy(df_defects, vuln, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74932ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[信息] Critical Variables Manipulation (CVM) 样本量为 79\n",
      "[信息] 已完成 Critical Variables Manipulation (CVM) 抽样并保存至 /mnt/linzw3/work/defistaking/3_Experiment/largeScale/3_samples/Critical Variables Manipulation (CVM)_sampled.xlsx\n",
      "[信息] Rewards without Timedelay (RT) 样本量为 82\n",
      "[信息] 已完成 Rewards without Timedelay (RT) 抽样并保存至 /mnt/linzw3/work/defistaking/3_Experiment/largeScale/3_samples/Rewards without Timedelay (RT)_sampled.xlsx\n",
      "[信息] Single Liquidity Pool Reliance (SLR) 样本量为 31\n",
      "[信息] 已完成 Single Liquidity Pool Reliance (SLR) 抽样并保存至 /mnt/linzw3/work/defistaking/3_Experiment/largeScale/3_samples/Single Liquidity Pool Reliance (SLR)_sampled.xlsx\n",
      "[信息] Omission in Status Update (OSU) 样本量为 87\n",
      "[信息] 已完成 Omission in Status Update (OSU) 抽样并保存至 /mnt/linzw3/work/defistaking/3_Experiment/largeScale/3_samples/Omission in Status Update (OSU)_sampled.xlsx\n",
      "[信息] Unsafe Verifications (UV) 样本量为 90\n",
      "[信息] 已完成 Unsafe Verifications (UV) 抽样并保存至 /mnt/linzw3/work/defistaking/3_Experiment/largeScale/3_samples/Unsafe Verifications (UV)_sampled.xlsx\n",
      "[信息] Unauthorized User Funds Access (UFA) 样本量为 87\n",
      "[信息] 已完成 Unauthorized User Funds Access (UFA) 抽样并保存至 /mnt/linzw3/work/defistaking/3_Experiment/largeScale/3_samples/Unauthorized User Funds Access (UFA)_sampled.xlsx\n"
     ]
    }
   ],
   "source": [
    "sample_output_folder = \"/mnt/linzw3/work/defistaking/3_Experiment/largeScale/3_samples\"\n",
    "output_sampled_contracts(df_defects_allChains, sample_output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c98d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复制FP sample for test\n",
    "testFP_chain_name = \"fantom\"\n",
    "testFP_contract_name = \"0f01D50C9A6dDe60a14E4e8875063cc79F6283E4_Boardroom\"\n",
    "\n",
    "testFP_contract_path = \"/mnt/linzw3/work/defistaking/1_Datasets/largeScale/final/\" + testFP_chain_name + \"/\" + testFP_contract_name + \".sol\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57151b0b",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "615f7813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/linzw3/work/defistaking/3_Experiment/largeScale/2_defects/ethereum/defects/b61b80d1ab9b2D306D2F989E63deD2B0410dA8ab_UNICURRYLTTRewards.json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_defects_all[\"Contract\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b63a4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_json_test = \"/mnt/linzw3/work/defistaking/3_Experiment/largeScale/2_defects/analyzable/ethereum/defects/b6a2452e8ee8c6d18bdad151935d29c1870598f7_ZEUSToken.json\"\n",
    "dict_defects_test = read_defects_results_perContract(path_json_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18b6116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_defects_all = read_defects_results_allChains(list_largeScale_defects_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fd591b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contract</th>\n",
       "      <th>Critical Variables Manipulation (CVM)</th>\n",
       "      <th>Rewards without Timedelay (RT)</th>\n",
       "      <th>Single Liquidity Pool Reliance (SLR)</th>\n",
       "      <th>Error or Omission in Status Update (ESU)</th>\n",
       "      <th>Unsafe Verifications (UV)</th>\n",
       "      <th>Unauthorized User Funds Access (UFA)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>/mnt/linzw3/work/defistaking/3_Experiment/larg...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Contract  \\\n",
       "0   /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "1   /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "2   /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "3   /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "4   /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "5   /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "6   /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "7   /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "8   /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "9   /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "10  /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "11  /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "12  /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "13  /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "14  /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "15  /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "16  /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "17  /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "18  /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "19  /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "20  /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "21  /mnt/linzw3/work/defistaking/3_Experiment/larg...   \n",
       "\n",
       "   Critical Variables Manipulation (CVM) Rewards without Timedelay (RT)  \\\n",
       "0                                   True                          False   \n",
       "1                                   True                           True   \n",
       "2                                   True                           True   \n",
       "3                                   True                           True   \n",
       "4                                   True                          False   \n",
       "5                                   True                           True   \n",
       "6                                   True                          False   \n",
       "7                                   True                          False   \n",
       "8                                   True                           True   \n",
       "9                                  False                          False   \n",
       "10                                  True                          False   \n",
       "11                                  True                          False   \n",
       "12                                  True                           True   \n",
       "13                                  True                          False   \n",
       "14                                  True                           True   \n",
       "15                                  True                           True   \n",
       "16                                  True                          False   \n",
       "17                                 False                          False   \n",
       "18                                  True                           True   \n",
       "19                                  True                           True   \n",
       "20                                  True                          False   \n",
       "21                                 False                          False   \n",
       "\n",
       "   Single Liquidity Pool Reliance (SLR)  \\\n",
       "0                                 False   \n",
       "1                                 False   \n",
       "2                                 False   \n",
       "3                                 False   \n",
       "4                                 False   \n",
       "5                                 False   \n",
       "6                                 False   \n",
       "7                                 False   \n",
       "8                                 False   \n",
       "9                                 False   \n",
       "10                                False   \n",
       "11                                False   \n",
       "12                                False   \n",
       "13                                False   \n",
       "14                                False   \n",
       "15                                False   \n",
       "16                                False   \n",
       "17                                False   \n",
       "18                                False   \n",
       "19                                False   \n",
       "20                                False   \n",
       "21                                False   \n",
       "\n",
       "   Error or Omission in Status Update (ESU) Unsafe Verifications (UV)  \\\n",
       "0                                      True                     False   \n",
       "1                                     False                     False   \n",
       "2                                      True                     False   \n",
       "3                                      True                     False   \n",
       "4                                      True                     False   \n",
       "5                                      True                     False   \n",
       "6                                      True                      True   \n",
       "7                                     False                      True   \n",
       "8                                      True                      True   \n",
       "9                                      True                      True   \n",
       "10                                     True                     False   \n",
       "11                                     True                     False   \n",
       "12                                     True                     False   \n",
       "13                                     True                     False   \n",
       "14                                     True                      True   \n",
       "15                                     True                     False   \n",
       "16                                    False                     False   \n",
       "17                                    False                     False   \n",
       "18                                     True                     False   \n",
       "19                                     True                     False   \n",
       "20                                     True                     False   \n",
       "21                                     True                     False   \n",
       "\n",
       "   Unauthorized User Funds Access (UFA)  \n",
       "0                                 False  \n",
       "1                                 False  \n",
       "2                                 False  \n",
       "3                                 False  \n",
       "4                                 False  \n",
       "5                                 False  \n",
       "6                                 False  \n",
       "7                                  True  \n",
       "8                                 False  \n",
       "9                                 False  \n",
       "10                                False  \n",
       "11                                False  \n",
       "12                                False  \n",
       "13                                False  \n",
       "14                                False  \n",
       "15                                False  \n",
       "16                                False  \n",
       "17                                False  \n",
       "18                                False  \n",
       "19                                False  \n",
       "20                                False  \n",
       "21                                False  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_defects_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
